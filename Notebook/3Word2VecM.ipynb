{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3.3.2 Word2Vec + Random Forest for Sentence Similarity"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T05:50:57.094789Z",
     "start_time": "2024-12-18T05:50:55.879909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from joblib import Parallel, delayed\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aswathshakthi/PycharmProjects/MLOps/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T05:51:01.373149Z",
     "start_time": "2024-12-18T05:51:01.360676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"/Users/aswathshakthi/PycharmProjects/MLOps/Semantic-Textual-Similarity-NLP/data/clinic_c.csv\"\n",
    "word2vec_path = \"/Users/aswathshakthi/PycharmProjects/MLOps/Semantic-Textual-Similarity-NLP/data/PubMed-and-PMC-w2v.bin\"\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(data_path)\n",
    "print(df.head())\n",
    "\n",
    "# Split data into train/test sets\n",
    "train_text1 = df[\"Sent1\"][:750].tolist()\n",
    "train_text2 = df[\"Sent2\"][:750].tolist()\n",
    "train_labels = df[\"Score\"][:750].tolist()\n",
    "\n",
    "test_text1 = df[\"Sent1\"][750:].tolist()\n",
    "test_text2 = df[\"Sent2\"][750:].tolist()\n",
    "test_labels = df[\"Score\"][750:].tolist()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Sent1  \\\n",
      "0  Insulin NPH Human [NOVOLIN N] 100 unit/mL susp...   \n",
      "1   Patient arrives ambulatory, Gait steady, Hist...   \n",
      "2   Peripheral IV site, established in the right ...   \n",
      "3   No: new confusion or inability to stay alert ...   \n",
      "4  Spent 15 minutes with the patient and greater ...   \n",
      "\n",
      "                                               Sent2  Score  \n",
      "0   Insulin NPH Human [NOVOLIN N] 100 unit/mL sus...   3.50  \n",
      "1   Complex assessment performed, Patient arrives...   2.50  \n",
      "2   Peripheral IV site, present prior to arrival,...   3.45  \n",
      "3   No: new confusion or inability to stay alert ...   4.00  \n",
      "4   Nurse visit ten minutes, over half of which w...   3.00  \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T05:51:22.552040Z",
     "start_time": "2024-12-18T05:51:02.460043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "print(f\"Word2Vec Model Loaded with {len(word_vectors)} words.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Model Loaded with 4087446 words.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T05:51:28.713147Z",
     "start_time": "2024-12-18T05:51:28.709804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def avg_feature_vector(sentence, model, num_features):\n",
    "    \"\"\"Compute the average feature vector for a sentence.\"\"\"\n",
    "    words = sentence.split()\n",
    "    feature_vec = np.zeros((num_features,), dtype='float32')\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in model:\n",
    "            n_words += 1\n",
    "            feature_vec += model[word]\n",
    "    if n_words > 0:\n",
    "        feature_vec /= n_words\n",
    "    return feature_vec\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-18T05:51:29.767507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_vectors(sentences, model, num_features):\n",
    "    \"\"\"Compute feature vectors for a list of sentences in parallel.\"\"\"\n",
    "    return Parallel(n_jobs=-1)(\n",
    "        delayed(avg_feature_vector)(sentence, model, num_features) for sentence in sentences\n",
    "    )\n",
    "\n",
    "# Compute feature vectors for train and test sets\n",
    "train_vecs1 = compute_vectors(train_text1, word_vectors, 200)\n",
    "train_vecs2 = compute_vectors(train_text2, word_vectors, 200)\n",
    "test_vecs1 = compute_vectors(test_text1, word_vectors, 200)\n",
    "test_vecs2 = compute_vectors(test_text2, word_vectors, 200)\n",
    "\n",
    "print(f\"Train Vecs1: {len(train_vecs1)}, Test Vecs1: {len(test_vecs1)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "reg1 = RandomForestRegressor(max_depth=6).fit(train_vecs1, train_labels)\n",
    "reg2 = RandomForestRegressor(max_depth=6).fit(train_vecs2, train_labels)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Predictions\n",
    "test_pred1 = reg1.predict(test_vecs1)\n",
    "test_pred2 = reg2.predict(test_vecs2)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse1 = mean_squared_error(test_labels, test_pred1)\n",
    "mse2 = mean_squared_error(test_labels, test_pred2)\n",
    "print(f\"MSE for Sentence 1: {mse1}\")\n",
    "print(f\"MSE for Sentence 2: {mse2}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_wmd(sentences1, sentences2, model):\n",
    "    \"\"\"Compute Word Mover's Distance (WMD) for paired sentences.\"\"\"\n",
    "    return [1 - model.wmdistance(sent1, sent2) for sent1, sent2 in zip(sentences1, sentences2)]\n",
    "\n",
    "# Train WMD Similarities\n",
    "train_wmd = compute_wmd(train_text1, train_text2, word_vectors)\n",
    "\n",
    "# Test WMD Similarities\n",
    "test_wmd = compute_wmd(test_text1, test_text2, word_vectors)\n",
    "\n",
    "print(f\"Sample WMD Train Similarities: {train_wmd[:5]}\")\n",
    "print(f\"Sample WMD Test Similarities: {test_wmd[:5]}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_corr, _ = pearsonr(train_wmd, train_labels)\n",
    "test_corr, _ = pearsonr(test_wmd, test_labels)\n",
    "\n",
    "print(f\"Pearson Correlation for Train: {train_corr:.5f}\")\n",
    "print(f\"Pearson Correlation for Test: {test_corr:.5f}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "results = {\n",
    "    \"mse1\": mse1,\n",
    "    \"mse2\": mse2,\n",
    "    \"train_corr\": train_corr,\n",
    "    \"test_corr\": test_corr,\n",
    "}\n",
    "print(\"Results:\", results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
